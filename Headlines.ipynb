{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP5nmZPhZUqWTDFCnINph7Q",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aanjalii2/Stock/blob/main/Headlines.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sp5Lc9VpJS1x",
        "outputId": "93588f59-165f-47e5-a50a-5c0df07ea568"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting to scrape Ratopati headlines...\n",
            "\n",
            "Scraping URL: https://www.ratopati.com/category/share-market (Page 1)\n",
            "‚Üí Total collected so far: 83 headlines\n",
            "Scraping URL: https://www.ratopati.com/category/share-market?page=2 (Page 2)\n",
            "‚Üí Total collected so far: 123 headlines\n",
            "Scraping URL: https://www.ratopati.com/category/share-market?page=3 (Page 3)\n",
            "‚Üí Total collected so far: 164 headlines\n",
            "Scraping URL: https://www.ratopati.com/category/share-market?page=4 (Page 4)\n",
            "‚Üí Total collected so far: 204 headlines\n",
            "Scraping URL: https://www.ratopati.com/category/share-market?page=5 (Page 5)\n",
            "‚Üí Total collected so far: 245 headlines\n",
            "Scraping URL: https://www.ratopati.com/category/share-market?page=6 (Page 6)\n",
            "‚Üí Total collected so far: 286 headlines\n",
            "Scraping URL: https://www.ratopati.com/category/share-market?page=7 (Page 7)\n",
            "‚Üí Total collected so far: 327 headlines\n",
            "Scraping URL: https://www.ratopati.com/category/share-market?page=8 (Page 8)\n",
            "‚Üí Total collected so far: 368 headlines\n",
            "Scraping URL: https://www.ratopati.com/category/share-market?page=9 (Page 9)\n",
            "‚Üí Total collected so far: 409 headlines\n",
            "Scraping URL: https://www.ratopati.com/category/share-market?page=10 (Page 10)\n",
            "‚Üí Total collected so far: 450 headlines\n",
            "Scraping URL: https://www.ratopati.com/category/share-market?page=11 (Page 11)\n",
            "‚Üí Total collected so far: 491 headlines\n",
            "Scraping URL: https://www.ratopati.com/category/share-market?page=12 (Page 12)\n",
            "‚Üí Total collected so far: 532 headlines\n",
            "Scraping URL: https://www.ratopati.com/category/share-market?page=13 (Page 13)\n",
            "‚Üí Total collected so far: 573 headlines\n",
            "Scraping URL: https://www.ratopati.com/category/share-market?page=14 (Page 14)\n",
            "‚Üí Total collected so far: 614 headlines\n",
            "Scraping URL: https://www.ratopati.com/category/share-market?page=15 (Page 15)\n",
            "‚Üí Total collected so far: 655 headlines\n",
            "Scraping URL: https://www.ratopati.com/category/share-market?page=16 (Page 16)\n",
            "‚Üí Total collected so far: 695 headlines\n",
            "Scraping URL: https://www.ratopati.com/category/share-market?page=17 (Page 17)\n",
            "‚Üí Total collected so far: 735 headlines\n",
            "Scraping URL: https://www.ratopati.com/category/share-market?page=18 (Page 18)\n",
            "‚Üí Total collected so far: 776 headlines\n",
            "\n",
            "‚úÖ Scraping complete. Total unique headlines collected: 776\n",
            "1. ‡§®‡•á‡§™‡•ç‡§∏‡•á ‡§™‡§∞‡§ø‡§∏‡•Ç‡§ö‡§ï ‡•ß‡•Ø.‡•´‡•¨ ‡§Ö‡§Ç‡§ï‡§≤‡•á ‡§µ‡•É‡§¶‡•ç‡§ß‡§ø\n",
            "2. ‡§∏‡•Ä‡§¨‡•Ä‡§Ü‡§à‡§è‡§≤‡§ï‡•ã ‡§™‡•ç‡§∞‡§Æ‡•Å‡§ñ ‡§ï‡§æ‡§∞‡•ç‡§Ø‡§ï‡§æ‡§∞‡•Ä ‡§Ö‡§ß‡§ø‡§ï‡•É‡§§‡§Æ‡§æ ‡§Ö‡§∞‡•ç‡§Ø‡§æ‡§≤ ‡§®‡§ø‡§Ø‡•Å‡§ï‡•ç‡§§\n",
            "3. ‡•´‡•≠ ‡§Ö‡§Ç‡§ï‡§≤‡•á ‡§ò‡§ü‡•ç‡§Ø‡•ã ‡§¨‡§ú‡§æ‡§∞, ‡§™‡§∞‡§ø‡§∏‡•Ç‡§ö‡§ï ‡•®‡•´‡•Æ‡•¶ ‡§¨‡§ø‡§®‡•ç‡§¶‡•Å‡§Æ‡§æ\n",
            "4. ‡§®‡•á‡§™‡•ç‡§∏‡•á ‡§∏‡•Ç‡§ö‡§ï ‡•Æ.‡•ß‡•Æ ‡§Ö‡§Ç‡§ï‡§≤‡•á ‡§ò‡§ü‡•ç‡§Ø‡•ã, ‡§ï‡§æ‡§∞‡•ã‡§¨‡§æ‡§∞‡§Æ‡§æ ‡§™‡§®‡§ø ‡§ó‡§ø‡§∞‡§æ‡§µ‡§ü\n",
            "5. ‡§∏‡•á‡§Ø‡§∞ ‡§¨‡§ú‡§æ‡§∞‡§Æ‡§æ ‡•™ ‡§Ö‡§Ç‡§ï‡§ï‡•ã ‡§µ‡•É‡§¶‡•ç‡§ß‡§ø, ‡§ï‡§æ‡§∞‡•ã‡§¨‡§æ‡§∞ ‡§∞‡§ï‡§Æ ‡§™‡§®‡§ø ‡§¨‡§¢‡•ç‡§Ø‡•ã\n",
            "6. ‡•®‡•¶‡•Æ‡•¶ ‡§Æ‡§æ ‡§∏‡•á‡§Ø‡§∞ ‡§¨‡§ú‡§æ‡§∞ : ‡§Æ‡§æ‡§∞‡•ç‡§ï‡•á‡§ü ‡§ï‡•ç‡§Ø‡§æ‡§™‡§ø‡§ü‡§≤‡§æ‡§á‡§ú‡•á‡§∂‡§® ‡§ù‡§®‡•ç‡§°‡•à ‡•™ ‡§ñ‡§∞‡•ç‡§¨‡§≤‡•á ‡§¨‡§¢‡•ç‡§Ø‡•ã\n",
            "7. ‡§ö‡§æ‡§∞ ‡§µ‡§∞‡•ç‡§∑‡§ï‡•à ‡§â‡§ö‡•ç‡§ö ‡§µ‡§ø‡§®‡•ç‡§¶‡•Å‡§Æ‡§æ ‡§™‡•Å‡§ó‡•á‡§™‡§õ‡§ø ‚Äò‡§Ü‡§§‡•ç‡§§‡§ø‡§è‚Äô ‡§≤‡§ó‡§æ‡§®‡•Ä‡§ï‡§∞‡•ç‡§§‡§æ, ‡§∏‡•á‡§Ø‡§∞ ‡§¨‡§ú‡§æ‡§∞‡§Æ‡§æ ‡•™‡•Æ ‡§Ö‡§ô‡•ç‡§ï‡§ï‡•ã ‡§ó‡§ø‡§∞‡§æ‡§µ‡§ü\n",
            "8. ‡§∏‡§æ‡§§‡§æ‡§Æ‡§æ ‡§®‡•á‡§™‡•ç‡§∏‡•á ‡•¨‡•´.‡•®‡•≠ ‡§Ö‡§Ç‡§ï‡§≤‡•á ‡§µ‡•É‡§¶‡•ç‡§ß‡§ø, ‡§™‡•Å‡§∞‡§æ‡§®‡•à ‡§≤‡§Ø‡§Æ‡§æ ‡§´‡§∞‡•ç‡§ï‡§ø‡§è‡§≤‡§æ ?\n",
            "9. ‡§Ü‡§∞‡§¨‡•Ä‡§¨‡•Ä ‡§∏‡•á‡§ï‡•ç‡§Ø‡•Å‡§∞‡§ø‡§ü‡§ø‡§ú ‡§ï‡§Æ‡•ç‡§™‡§®‡•Ä‡§≤‡•á ‡§™‡§æ‡§Ø‡•ã ‡§ß‡§ø‡§§‡•ã‡§™‡§§‡•ç‡§∞ ‡§µ‡•ç‡§Ø‡§µ‡§∏‡§æ‡§Ø ‡§ó‡§∞‡•ç‡§®‡•á ‡§Ö‡§®‡•Å‡§Æ‡§§‡§ø‡§™‡§§‡•ç‡§∞\n",
            "10. ‡•™.‡•´‡•Ø ‡§Ö‡§Ç‡§ï‡§≤‡•á ‡§ò‡§ü‡•ç‡§Ø‡•ã ‡§∏‡•á‡§Ø‡§∞ ‡§¨‡§ú‡§æ‡§∞, ‡•´ ‡§Ö‡§∞‡•ç‡§¨‡§≠‡§®‡•ç‡§¶‡§æ ‡§¨‡§¢‡•Ä‡§ï‡•ã ‡§ï‡§æ‡§∞‡•ã‡§¨‡§æ‡§∞\n",
            "\n",
            "üìÅ Headlines saved to ratopati_headlines.txt\n",
            "üìÅ Headlines saved to ratopati_headlines.csv\n"
          ]
        }
      ],
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import time\n",
        "import random\n",
        "import pandas as pd\n",
        "\n",
        "def scrape_ratopati_headlines(num_headlines_needed=750, max_pages_to_check=90):\n",
        "    base_url = \"https://www.ratopati.com/category/share-market\"\n",
        "    headers = {\n",
        "        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64)'\n",
        "    }\n",
        "\n",
        "    unique_headlines = set()\n",
        "    page_num = 1\n",
        "\n",
        "    print(\"Starting to scrape Ratopati headlines...\\n\")\n",
        "\n",
        "    while len(unique_headlines) < num_headlines_needed and page_num <= max_pages_to_check:\n",
        "        if page_num == 1:\n",
        "            url = base_url\n",
        "        else:\n",
        "            url = f\"{base_url}?page={page_num}\"  # ‚Üê fixed this line\n",
        "\n",
        "        print(f\"Scraping URL: {url} (Page {page_num})\")\n",
        "\n",
        "        try:\n",
        "            response = requests.get(url, headers=headers, timeout=10)\n",
        "            response.raise_for_status()\n",
        "            soup = BeautifulSoup(response.text, 'html.parser')\n",
        "\n",
        "            # Collect headline tags\n",
        "            headlines_on_page = soup.find_all(['h2', 'h3'], class_=['title', 'news-title', 'post-title'])\n",
        "            article_links = soup.find_all('a', class_=['post-link', 'read-more-link'])\n",
        "\n",
        "            # Extract from <h2>/<h3>\n",
        "            for element in headlines_on_page:\n",
        "                headline_text = element.get_text(strip=True)\n",
        "                if headline_text and len(headline_text) > 10:\n",
        "                    unique_headlines.add(headline_text)\n",
        "\n",
        "            # Extract from <a> tags too\n",
        "            for link in article_links:\n",
        "                headline_text = link.get_text(strip=True)\n",
        "                if headline_text and len(headline_text) > 10:\n",
        "                    unique_headlines.add(headline_text)\n",
        "\n",
        "                # Try inner headline tag\n",
        "                child_headline = link.find(['h2', 'h3'])\n",
        "                if child_headline:\n",
        "                    child_text = child_headline.get_text(strip=True)\n",
        "                    if child_text and len(child_text) > 10:\n",
        "                        unique_headlines.add(child_text)\n",
        "\n",
        "            print(f\"‚Üí Total collected so far: {len(unique_headlines)} headlines\")\n",
        "\n",
        "            page_num += 1\n",
        "            time.sleep(random.uniform(1, 3))\n",
        "\n",
        "        except requests.exceptions.RequestException as e:\n",
        "            print(f\"Error fetching {url}: {e}\")\n",
        "            print(\"Retrying after a short delay...\\n\")\n",
        "            time.sleep(5)\n",
        "            continue\n",
        "\n",
        "    return list(unique_headlines)\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    headlines = scrape_ratopati_headlines(num_headlines_needed=750, max_pages_to_check=90)\n",
        "\n",
        "    print(f\"\\n‚úÖ Scraping complete. Total unique headlines collected: {len(headlines)}\")\n",
        "    for i, headline in enumerate(headlines[:10], 1):\n",
        "        print(f\"{i}. {headline}\")\n",
        "\n",
        "    # Save to text\n",
        "    with open(\"ratopati_headlines.txt\", \"w\", encoding=\"utf-8\") as f:\n",
        "        for headline in headlines:\n",
        "            f.write(headline + \"\\n\")\n",
        "    print(\"\\nüìÅ Headlines saved to ratopati_headlines.txt\")\n",
        "\n",
        "    # Also save to CSV\n",
        "    df = pd.DataFrame({'headline': headlines})\n",
        "    df.to_csv(\"ratopati_headlines.csv\", index=False, encoding=\"utf-8-sig\")\n",
        "    print(\"üìÅ Headlines saved to ratopati_headlines.csv\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download(\"ratopati_headlines.csv\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "ccwMO8SqM0Ab",
        "outputId": "37a00f7e-3bb7-4f13-f243-3f51b143c7a3"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_d45f12c1-b27a-463e-905f-d2637a84b76e\", \"ratopati_headlines.csv\", 114691)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bu0t2eyBND_u"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}